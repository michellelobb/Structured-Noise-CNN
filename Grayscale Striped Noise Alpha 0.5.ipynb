{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db13e3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "import scipy.signal\n",
    "from skimage.restoration import denoise_tv_bregman\n",
    "from skimage import restoration\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67d7cfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(200)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.config.optimizer.set_jit(False) # Start with XLA disabled.\n",
    "\n",
    "def load_data():\n",
    "  fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "  (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "  x_train = x_train.astype('float32') / 256\n",
    "  x_test = x_test.astype('float32') / 256\n",
    "\n",
    "  # Convert class vectors to binary class matrices.\n",
    "  y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "  y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "  return ((x_train, y_train), (x_test, y_test))\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "img = Image.new('L', (28, 28), 255)\n",
    "draw = ImageDraw.Draw(img)\n",
    "for y in range(5, 91, 4):\n",
    "    draw.line((32, y, 0, y), (0), 2)\n",
    "\n",
    "def struct_noise(image):\n",
    "   im = Image.fromarray((image * 255).astype(np.uint8)) \n",
    "   noisyimage = Image.blend(im, img, 0.5)\n",
    "   return noisyimage\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#test 1: train0 test0 = base splits\n",
    "\n",
    "#test 2: train0 test75\n",
    "a,b,an,bn = train_test_split(x_test, y_test, test_size=0.25, random_state=44)\n",
    "a0 = np.empty_like(a)\n",
    "y2 = np.empty_like(an)\n",
    "ytv2 = np.empty_like(an)\n",
    "atv = np.empty_like(a)\n",
    "for j in range(len(a)):\n",
    "    a0[j] = struct_noise(a[j])\n",
    "    atv[j] = skimage.restoration.denoise_tv_bregman(a0[j])\n",
    "    y2[j] = an[j]\n",
    "    ytv2[j] = an[j]\n",
    "a0 = np.concatenate((a0,b))\n",
    "atv = np.concatenate((atv,b))\n",
    "y2 = np.concatenate((y2,bn))\n",
    "ytv2 = np.concatenate((ytv2, bn))\n",
    "\n",
    "#test 3: train0 test50\n",
    "c,d,cn,dn = train_test_split(x_test, y_test, test_size=0.50, random_state=44)\n",
    "c0 = np.empty_like(c)\n",
    "ctv = np.empty_like(c)\n",
    "y3 = np.empty_like(cn)\n",
    "ytv3 = np.empty_like(cn)\n",
    "for j in range(len(c)):\n",
    "    c0[j] = struct_noise(c[j])\n",
    "    ctv[j] = skimage.restoration.denoise_tv_bregman(c0[j])\n",
    "    y3[j] = cn[j]\n",
    "    ytv3[j] = cn[j]\n",
    "c0 = np.concatenate((c0,d))\n",
    "ctv = np.concatenate((ctv,d))\n",
    "y3 = np.concatenate((y3,dn))\n",
    "ytv3 = np.concatenate((ytv3, dn))\n",
    "\n",
    "#test 4: train0 test25\n",
    "e,f,en,fn = train_test_split(x_test,y_test, test_size=0.75, random_state=44)\n",
    "e0 = np.empty_like(e)\n",
    "etv = np.empty_like(e)\n",
    "y4 = np.empty_like(en)\n",
    "ytv4 = np.empty_like(en)\n",
    "for j in range(len(e)):\n",
    "    e0[j] = struct_noise(e[j])\n",
    "    etv[j] = skimage.restoration.denoise_tv_bregman(e0[j])\n",
    "    y4[j] = en[j]\n",
    "    ytv4[j] = en[j]\n",
    "e0 = np.concatenate((e0,f))\n",
    "etv = np.concatenate((etv,f))\n",
    "y4 = np.concatenate((y4,fn))\n",
    "ytv4 = np.concatenate((ytv4, fn))\n",
    "\n",
    "#test 5: train0 test100\n",
    "g0 = np.empty_like(x_test)\n",
    "gtv = np.empty_like(x_test)\n",
    "for j in range(len(x_test)):\n",
    "    g0[j] = struct_noise(x_test[j])\n",
    "    gtv[j] = skimage.restoration.denoise_tv_bregman(g0[j])\n",
    "    \n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd372306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3)),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same'),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3)),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Activation('softmax')\n",
    "  ])\n",
    "\n",
    "model = generate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e62133bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "188/188 [==============================] - 23s 119ms/step - loss: 1.2473 - accuracy: 0.5448 - val_loss: 0.6600 - val_accuracy: 0.7625\n",
      "Epoch 2/25\n",
      "188/188 [==============================] - 25s 134ms/step - loss: 0.6784 - accuracy: 0.7475 - val_loss: 0.5459 - val_accuracy: 0.7947\n",
      "Epoch 3/25\n",
      "188/188 [==============================] - 23s 123ms/step - loss: 0.5832 - accuracy: 0.7828 - val_loss: 0.4834 - val_accuracy: 0.8254\n",
      "Epoch 4/25\n",
      "188/188 [==============================] - 24s 127ms/step - loss: 0.5256 - accuracy: 0.8058 - val_loss: 0.4425 - val_accuracy: 0.8451\n",
      "Epoch 5/25\n",
      "188/188 [==============================] - 26s 141ms/step - loss: 0.4894 - accuracy: 0.8220 - val_loss: 0.4148 - val_accuracy: 0.8523\n",
      "Epoch 6/25\n",
      "188/188 [==============================] - 24s 128ms/step - loss: 0.4630 - accuracy: 0.8301 - val_loss: 0.3987 - val_accuracy: 0.8591\n",
      "Epoch 7/25\n",
      "188/188 [==============================] - 24s 130ms/step - loss: 0.4360 - accuracy: 0.8409 - val_loss: 0.3749 - val_accuracy: 0.8658\n",
      "Epoch 8/25\n",
      "188/188 [==============================] - 24s 128ms/step - loss: 0.4163 - accuracy: 0.8492 - val_loss: 0.3550 - val_accuracy: 0.8737\n",
      "Epoch 9/25\n",
      "188/188 [==============================] - 27s 145ms/step - loss: 0.3982 - accuracy: 0.8551 - val_loss: 0.3420 - val_accuracy: 0.8773\n",
      "Epoch 10/25\n",
      "188/188 [==============================] - 25s 136ms/step - loss: 0.3830 - accuracy: 0.8613 - val_loss: 0.3342 - val_accuracy: 0.8785\n",
      "Epoch 11/25\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.3747 - accuracy: 0.8639 - val_loss: 0.3201 - val_accuracy: 0.8833\n",
      "Epoch 12/25\n",
      "188/188 [==============================] - 25s 135ms/step - loss: 0.3561 - accuracy: 0.8697 - val_loss: 0.3128 - val_accuracy: 0.8887\n",
      "Epoch 13/25\n",
      "188/188 [==============================] - 24s 129ms/step - loss: 0.3487 - accuracy: 0.8738 - val_loss: 0.3030 - val_accuracy: 0.8921\n",
      "Epoch 14/25\n",
      "188/188 [==============================] - 30s 159ms/step - loss: 0.3389 - accuracy: 0.8765 - val_loss: 0.2978 - val_accuracy: 0.8936\n",
      "Epoch 15/25\n",
      "188/188 [==============================] - 30s 158ms/step - loss: 0.3306 - accuracy: 0.8802 - val_loss: 0.2924 - val_accuracy: 0.8943\n",
      "Epoch 16/25\n",
      "188/188 [==============================] - 25s 136ms/step - loss: 0.3243 - accuracy: 0.8824 - val_loss: 0.2863 - val_accuracy: 0.8988\n",
      "Epoch 17/25\n",
      "188/188 [==============================] - 23s 123ms/step - loss: 0.3164 - accuracy: 0.8851 - val_loss: 0.2815 - val_accuracy: 0.8990\n",
      "Epoch 18/25\n",
      "188/188 [==============================] - 22s 118ms/step - loss: 0.3073 - accuracy: 0.8887 - val_loss: 0.2729 - val_accuracy: 0.9022\n",
      "Epoch 19/25\n",
      "188/188 [==============================] - 22s 116ms/step - loss: 0.3016 - accuracy: 0.8895 - val_loss: 0.2720 - val_accuracy: 0.9016\n",
      "Epoch 20/25\n",
      "188/188 [==============================] - 22s 116ms/step - loss: 0.2983 - accuracy: 0.8917 - val_loss: 0.2668 - val_accuracy: 0.9043\n",
      "Epoch 21/25\n",
      "188/188 [==============================] - 22s 119ms/step - loss: 0.2923 - accuracy: 0.8930 - val_loss: 0.2612 - val_accuracy: 0.9057\n",
      "Epoch 22/25\n",
      "188/188 [==============================] - 23s 124ms/step - loss: 0.2856 - accuracy: 0.8961 - val_loss: 0.2653 - val_accuracy: 0.9022\n",
      "Epoch 23/25\n",
      "188/188 [==============================] - 24s 128ms/step - loss: 0.2829 - accuracy: 0.8970 - val_loss: 0.2575 - val_accuracy: 0.9082\n",
      "Epoch 24/25\n",
      "188/188 [==============================] - 24s 126ms/step - loss: 0.2742 - accuracy: 0.8981 - val_loss: 0.2527 - val_accuracy: 0.9078\n",
      "Epoch 25/25\n",
      "188/188 [==============================] - 24s 127ms/step - loss: 0.2701 - accuracy: 0.9007 - val_loss: 0.2484 - val_accuracy: 0.9088\n"
     ]
    }
   ],
   "source": [
    "def compile_model(model):\n",
    "  opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "model = compile_model(model)\n",
    "\n",
    "def train_model(model, x_train, y_train, x_test, y_test, epochs=25):\n",
    "  model.fit(x_train, y_train, batch_size=256, epochs=epochs, validation_data=(x_test, y_test), shuffle=True)\n",
    "\n",
    "train_model(model, x_train,y_train, x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc197ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2628 - accuracy: 0.9037\n",
      "Benchmark Test loss: 0.26277318596839905\n",
      "Benchmark Test accuracy: 0.9036999940872192\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 103.0884 - accuracy: 0.7373\n",
      "B75 Test loss: 103.08842468261719\n",
      "B75 Test accuracy: 0.7372999787330627\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 103.1084 - accuracy: 0.7363\n",
      "T75 Test loss: 103.10842895507812\n",
      "T75 Test accuracy: 0.736299991607666\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 70.2146 - accuracy: 0.7899\n",
      "B50 Test loss: 70.21458435058594\n",
      "B50 Test accuracy: 0.789900004863739\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 70.2407 - accuracy: 0.7894\n",
      "T50 Test loss: 70.24073791503906\n",
      "T50 Test accuracy: 0.7893999814987183\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 36.0404 - accuracy: 0.8438\n",
      "B25 Test loss: 36.04035186767578\n",
      "B25 Test accuracy: 0.8438000082969666\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 36.0913 - accuracy: 0.8438\n",
      "T25 Test loss: 36.091339111328125\n",
      "T25 Test accuracy: 0.8438000082969666\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 138.9227 - accuracy: 0.6757\n",
      "B100 Test loss: 138.92271423339844\n",
      "B100 Test accuracy: 0.6757000088691711\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 138.9439 - accuracy: 0.6744\n",
      "T100 Test loss: 138.94387817382812\n",
      "T100 Test accuracy: 0.6743999719619751\n"
     ]
    }
   ],
   "source": [
    "scores_t1 = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Benchmark Test loss:', scores_t1[0])\n",
    "print('Benchmark Test accuracy:', scores_t1[1])\n",
    "\n",
    "base_scores_t2 = model.evaluate(a0, y2, verbose=1)\n",
    "print('B75 Test loss:', base_scores_t2[0])\n",
    "print('B75 Test accuracy:', base_scores_t2[1])\n",
    "\n",
    "tv_scores_t2 = model.evaluate(atv, ytv2, verbose=1)\n",
    "print('T75 Test loss:', tv_scores_t2[0])\n",
    "print('T75 Test accuracy:', tv_scores_t2[1])\n",
    "\n",
    "base_scores_t3 = model.evaluate(c0, y3, verbose=1)\n",
    "print('B50 Test loss:', base_scores_t3[0])\n",
    "print('B50 Test accuracy:', base_scores_t3[1])\n",
    "\n",
    "tv_scores_t3 = model.evaluate(ctv, ytv3, verbose=1)\n",
    "print('T50 Test loss:', tv_scores_t3[0])\n",
    "print('T50 Test accuracy:', tv_scores_t3[1])\n",
    "\n",
    "base_scores_t4 = model.evaluate(e0, y4, verbose=1)\n",
    "print('B25 Test loss:', base_scores_t4[0])\n",
    "print('B25 Test accuracy:', base_scores_t4[1])\n",
    "\n",
    "tv_scores_t4 = model.evaluate(etv, ytv4, verbose=1)\n",
    "print('T25 Test loss:', tv_scores_t4[0])\n",
    "print('T25 Test accuracy:', tv_scores_t4[1])\n",
    "\n",
    "base_scores_t5 = model.evaluate(g0, y_test, verbose=1)\n",
    "print('B100 Test loss:', base_scores_t5[0])\n",
    "print('B100 Test accuracy:', base_scores_t5[1])\n",
    "\n",
    "tv_scores_t5 = model.evaluate(gtv, y_test, verbose=1)\n",
    "print('T100 Test loss:', tv_scores_t5[0])\n",
    "print('T100 Test accuracy:', tv_scores_t5[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
