{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b0fb61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "import scipy.signal\n",
    "from skimage.restoration import denoise_tv_bregman\n",
    "from skimage import restoration\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5453f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(200)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.config.optimizer.set_jit(False) # Start with XLA disabled.\n",
    "\n",
    "def load_data():\n",
    "  fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "  (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "  x_train = x_train.astype('float32') / 256\n",
    "  x_test = x_test.astype('float32') / 256\n",
    "\n",
    "  # Convert class vectors to binary class matrices.\n",
    "  y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "  y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "  return ((x_train, y_train), (x_test, y_test))\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "img = Image.new('L', (28, 28), 255)\n",
    "draw = ImageDraw.Draw(img)\n",
    "for y in range(5, 91, 4):\n",
    "    draw.line((32, y, 0, y), (0), 2)\n",
    "\n",
    "def struct_noise(image):\n",
    "   im = Image.fromarray((image * 255).astype(np.uint8)) \n",
    "   noisyimage = Image.blend(im, img, 0.25)\n",
    "   return noisyimage\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#test 1: train0 test0 = base splits\n",
    "\n",
    "#test 2: train0 test75\n",
    "a,b,an,bn = train_test_split(x_test, y_test, test_size=0.25, random_state=44)\n",
    "a0 = np.empty_like(a)\n",
    "y2 = np.empty_like(an)\n",
    "ytv2 = np.empty_like(an)\n",
    "atv = np.empty_like(a)\n",
    "for j in range(len(a)):\n",
    "    a0[j] = struct_noise(a[j])\n",
    "    atv[j] = skimage.restoration.denoise_tv_bregman(a0[j])\n",
    "    y2[j] = an[j]\n",
    "    ytv2[j] = an[j]\n",
    "a0 = np.concatenate((a0,b))\n",
    "atv = np.concatenate((atv,b))\n",
    "y2 = np.concatenate((y2,bn))\n",
    "ytv2 = np.concatenate((ytv2, bn))\n",
    "\n",
    "#test 3: train0 test50\n",
    "c,d,cn,dn = train_test_split(x_test, y_test, test_size=0.50, random_state=44)\n",
    "c0 = np.empty_like(c)\n",
    "ctv = np.empty_like(c)\n",
    "y3 = np.empty_like(cn)\n",
    "ytv3 = np.empty_like(cn)\n",
    "for j in range(len(c)):\n",
    "    c0[j] = struct_noise(c[j])\n",
    "    ctv[j] = skimage.restoration.denoise_tv_bregman(c0[j])\n",
    "    y3[j] = cn[j]\n",
    "    ytv3[j] = cn[j]\n",
    "c0 = np.concatenate((c0,d))\n",
    "ctv = np.concatenate((ctv,d))\n",
    "y3 = np.concatenate((y3,dn))\n",
    "ytv3 = np.concatenate((ytv3, dn))\n",
    "\n",
    "#test 4: train0 test25\n",
    "e,f,en,fn = train_test_split(x_test,y_test, test_size=0.75, random_state=44)\n",
    "e0 = np.empty_like(e)\n",
    "etv = np.empty_like(e)\n",
    "y4 = np.empty_like(en)\n",
    "ytv4 = np.empty_like(en)\n",
    "for j in range(len(e)):\n",
    "    e0[j] = struct_noise(e[j])\n",
    "    etv[j] = skimage.restoration.denoise_tv_bregman(e0[j])\n",
    "    y4[j] = en[j]\n",
    "    ytv4[j] = en[j]\n",
    "e0 = np.concatenate((e0,f))\n",
    "etv = np.concatenate((etv,f))\n",
    "y4 = np.concatenate((y4,fn))\n",
    "ytv4 = np.concatenate((ytv4, fn))\n",
    "\n",
    "#test 5: train0 test100\n",
    "g0 = np.empty_like(x_test)\n",
    "gtv = np.empty_like(x_test)\n",
    "for j in range(len(x_test)):\n",
    "    g0[j] = struct_noise(x_test[j])\n",
    "    gtv[j] = skimage.restoration.denoise_tv_bregman(g0[j])\n",
    "    \n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0bdb4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3)),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same'),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3)),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Activation('softmax')\n",
    "  ])\n",
    "\n",
    "model = generate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72190643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "188/188 [==============================] - 24s 123ms/step - loss: 1.2366 - accuracy: 0.5489 - val_loss: 0.6921 - val_accuracy: 0.7478\n",
      "Epoch 2/25\n",
      "188/188 [==============================] - 25s 131ms/step - loss: 0.6966 - accuracy: 0.7381 - val_loss: 0.5634 - val_accuracy: 0.7889\n",
      "Epoch 3/25\n",
      "188/188 [==============================] - 25s 132ms/step - loss: 0.6020 - accuracy: 0.7717 - val_loss: 0.5085 - val_accuracy: 0.8144\n",
      "Epoch 4/25\n",
      "188/188 [==============================] - 28s 147ms/step - loss: 0.5446 - accuracy: 0.7965 - val_loss: 0.4687 - val_accuracy: 0.8291\n",
      "Epoch 5/25\n",
      "188/188 [==============================] - 25s 131ms/step - loss: 0.5108 - accuracy: 0.8117 - val_loss: 0.4399 - val_accuracy: 0.8418\n",
      "Epoch 6/25\n",
      "188/188 [==============================] - 25s 134ms/step - loss: 0.4792 - accuracy: 0.8239 - val_loss: 0.4107 - val_accuracy: 0.8537\n",
      "Epoch 7/25\n",
      "188/188 [==============================] - 25s 131ms/step - loss: 0.4559 - accuracy: 0.8318 - val_loss: 0.3960 - val_accuracy: 0.8597\n",
      "Epoch 8/25\n",
      "188/188 [==============================] - 25s 131ms/step - loss: 0.4380 - accuracy: 0.8390 - val_loss: 0.3764 - val_accuracy: 0.8655\n",
      "Epoch 9/25\n",
      "188/188 [==============================] - 25s 131ms/step - loss: 0.4182 - accuracy: 0.8474 - val_loss: 0.3640 - val_accuracy: 0.8684\n",
      "Epoch 10/25\n",
      "188/188 [==============================] - 25s 133ms/step - loss: 0.4053 - accuracy: 0.8518 - val_loss: 0.3526 - val_accuracy: 0.8727\n",
      "Epoch 11/25\n",
      "188/188 [==============================] - 25s 131ms/step - loss: 0.3910 - accuracy: 0.8561 - val_loss: 0.3451 - val_accuracy: 0.8727\n",
      "Epoch 12/25\n",
      "188/188 [==============================] - 30s 162ms/step - loss: 0.3775 - accuracy: 0.8622 - val_loss: 0.3320 - val_accuracy: 0.8773\n",
      "Epoch 13/25\n",
      "188/188 [==============================] - 25s 135ms/step - loss: 0.3678 - accuracy: 0.8650 - val_loss: 0.3295 - val_accuracy: 0.8770\n",
      "Epoch 14/25\n",
      "188/188 [==============================] - 25s 131ms/step - loss: 0.3561 - accuracy: 0.8696 - val_loss: 0.3157 - val_accuracy: 0.8832\n",
      "Epoch 15/25\n",
      "188/188 [==============================] - 26s 138ms/step - loss: 0.3490 - accuracy: 0.8717 - val_loss: 0.3103 - val_accuracy: 0.8840\n",
      "Epoch 16/25\n",
      "188/188 [==============================] - 25s 132ms/step - loss: 0.3411 - accuracy: 0.8755 - val_loss: 0.3060 - val_accuracy: 0.8845\n",
      "Epoch 17/25\n",
      "188/188 [==============================] - 26s 140ms/step - loss: 0.3323 - accuracy: 0.8773 - val_loss: 0.2974 - val_accuracy: 0.8893\n",
      "Epoch 18/25\n",
      "188/188 [==============================] - 24s 129ms/step - loss: 0.3283 - accuracy: 0.8788 - val_loss: 0.2922 - val_accuracy: 0.8905\n",
      "Epoch 19/25\n",
      "188/188 [==============================] - 25s 130ms/step - loss: 0.3228 - accuracy: 0.8807 - val_loss: 0.2869 - val_accuracy: 0.8911\n",
      "Epoch 20/25\n",
      "188/188 [==============================] - 24s 129ms/step - loss: 0.3140 - accuracy: 0.8838 - val_loss: 0.2797 - val_accuracy: 0.8964\n",
      "Epoch 21/25\n",
      "188/188 [==============================] - 24s 129ms/step - loss: 0.3084 - accuracy: 0.8862 - val_loss: 0.2775 - val_accuracy: 0.8962\n",
      "Epoch 22/25\n",
      "188/188 [==============================] - 25s 131ms/step - loss: 0.3057 - accuracy: 0.8884 - val_loss: 0.2718 - val_accuracy: 0.8991\n",
      "Epoch 23/25\n",
      "188/188 [==============================] - 24s 128ms/step - loss: 0.2963 - accuracy: 0.8904 - val_loss: 0.2676 - val_accuracy: 0.9008\n",
      "Epoch 24/25\n",
      "188/188 [==============================] - 24s 129ms/step - loss: 0.2920 - accuracy: 0.8924 - val_loss: 0.2635 - val_accuracy: 0.9029\n",
      "Epoch 25/25\n",
      "188/188 [==============================] - 28s 147ms/step - loss: 0.2858 - accuracy: 0.8932 - val_loss: 0.2659 - val_accuracy: 0.9016\n"
     ]
    }
   ],
   "source": [
    "def compile_model(model):\n",
    "  opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "model = compile_model(model)\n",
    "\n",
    "def train_model(model, x_train, y_train, x_test, y_test, epochs=25):\n",
    "  model.fit(x_train, y_train, batch_size=256, epochs=epochs, validation_data=(x_test, y_test), shuffle=True)\n",
    "\n",
    "train_model(model, x_train,y_train, x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df85a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2827 - accuracy: 0.8956\n",
      "Benchmark Test loss: 0.2826685905456543\n",
      "Benchmark Test accuracy: 0.8956000208854675\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 13.7013 - accuracy: 0.8876\n",
      "B75 Test loss: 13.701338768005371\n",
      "B75 Test accuracy: 0.8876000046730042\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 14.2117 - accuracy: 0.8857\n",
      "T75 Test loss: 14.211710929870605\n",
      "T75 Test accuracy: 0.885699987411499\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 8.9622 - accuracy: 0.8906\n",
      "B50 Test loss: 8.962180137634277\n",
      "B50 Test accuracy: 0.8906000256538391\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 9.2674 - accuracy: 0.8894\n",
      "T50 Test loss: 9.267353057861328\n",
      "T50 Test accuracy: 0.8894000053405762\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 4.5837 - accuracy: 0.8927\n",
      "B25 Test loss: 4.583747386932373\n",
      "B25 Test accuracy: 0.8927000164985657\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 4.7471 - accuracy: 0.8918\n",
      "T25 Test loss: 4.747090816497803\n",
      "T25 Test accuracy: 0.8917999863624573\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 18.4899 - accuracy: 0.8819\n",
      "B100 Test loss: 18.489877700805664\n",
      "B100 Test accuracy: 0.8819000124931335\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 19.1471 - accuracy: 0.8795\n",
      "T100 Test loss: 19.147050857543945\n",
      "T100 Test accuracy: 0.8794999718666077\n"
     ]
    }
   ],
   "source": [
    "scores_t1 = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Benchmark Test loss:', scores_t1[0])\n",
    "print('Benchmark Test accuracy:', scores_t1[1])\n",
    "\n",
    "base_scores_t2 = model.evaluate(a0, y2, verbose=1)\n",
    "print('B75 Test loss:', base_scores_t2[0])\n",
    "print('B75 Test accuracy:', base_scores_t2[1])\n",
    "\n",
    "tv_scores_t2 = model.evaluate(atv, ytv2, verbose=1)\n",
    "print('T75 Test loss:', tv_scores_t2[0])\n",
    "print('T75 Test accuracy:', tv_scores_t2[1])\n",
    "\n",
    "base_scores_t3 = model.evaluate(c0, y3, verbose=1)\n",
    "print('B50 Test loss:', base_scores_t3[0])\n",
    "print('B50 Test accuracy:', base_scores_t3[1])\n",
    "\n",
    "tv_scores_t3 = model.evaluate(ctv, ytv3, verbose=1)\n",
    "print('T50 Test loss:', tv_scores_t3[0])\n",
    "print('T50 Test accuracy:', tv_scores_t3[1])\n",
    "\n",
    "base_scores_t4 = model.evaluate(e0, y4, verbose=1)\n",
    "print('B25 Test loss:', base_scores_t4[0])\n",
    "print('B25 Test accuracy:', base_scores_t4[1])\n",
    "\n",
    "tv_scores_t4 = model.evaluate(etv, ytv4, verbose=1)\n",
    "print('T25 Test loss:', tv_scores_t4[0])\n",
    "print('T25 Test accuracy:', tv_scores_t4[1])\n",
    "\n",
    "base_scores_t5 = model.evaluate(g0, y_test, verbose=1)\n",
    "print('B100 Test loss:', base_scores_t5[0])\n",
    "print('B100 Test accuracy:', base_scores_t5[1])\n",
    "\n",
    "tv_scores_t5 = model.evaluate(gtv, y_test, verbose=1)\n",
    "print('T100 Test loss:', tv_scores_t5[0])\n",
    "print('T100 Test accuracy:', tv_scores_t5[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
